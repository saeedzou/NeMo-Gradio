{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéôÔ∏è YouTube Persian ASR, Summarization & Translation\n",
        "Welcome to this interactive Google Colab notebook!  \n",
        "You can:\n",
        "‚úÖ Enter a YouTube link  \n",
        "‚úÖ Transcribe Persian speech into text  \n",
        "‚úÖ Translate, Summarize, and Punctuate it using Gemini models\n",
        "\n",
        "üëá Run all cells below. It will open a Gradio app. You can play around with it in this notebook or open the public URL.\n",
        "\n",
        "‚ÄºÔ∏è If you were detected as a bot and received PO_TOKEN related error, delete runtime and re-run all cells again.\n",
        "\n",
        "---\n",
        "\n",
        "üìú This application is licensed under Creative Commons Attribution-NonCommercial 4.0 (CC BY-NC 4.0).\n",
        "\n",
        "If you're interested in commercial applications, please contact us at:\n",
        "\n",
        "‚úâÔ∏è Email: saeedzou2012@gmail.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "D7btE3DiBMK2"
      },
      "outputs": [],
      "source": [
        "# @title Installation requirements\n",
        "%%capture\n",
        "!pip install gradio gradio_client pytubefix pydub\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import requests\n",
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "from gradio_client import Client, handle_file\n",
        "\n",
        "# Hugging Face Space Name\n",
        "HF_SPACE = \"saeedzou/Persian_ASR_Text_Summarization\"\n",
        "client = Client(HF_SPACE)\n",
        "\n",
        "# Function to download YouTube audio\n",
        "def download_audio(youtube_url):\n",
        "    try:\n",
        "        yt = YouTube(youtube_url, on_progress_callback=on_progress)\n",
        "        audio_stream = yt.streams.get_audio_only()\n",
        "        filename = audio_stream.download(filename=\"youtube_audio.mp4\")  # Save as mp4\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Function to transcribe using Hugging Face API\n",
        "def transcribe_audio(youtube_url):\n",
        "    audio_path = download_audio(youtube_url)\n",
        "\n",
        "    if \"Error\" in audio_path:\n",
        "        return audio_path, \"\", \"\", \"\"\n",
        "\n",
        "    result = client.predict(audio=handle_file(audio_path), api_name=\"/transcribe\")\n",
        "\n",
        "    return result, \"\", \"\", \"\"  # Empty translation & summary initially\n",
        "\n",
        "# Function to translate\n",
        "def translate_text(text, target_language, model_sel):\n",
        "    result = client.predict(text=text, target_language=target_language, model_sel=model_sel, api_name=\"/translate\")\n",
        "    return result\n",
        "\n",
        "# Function to summarize\n",
        "def summarize_text(text, word_count, model_sel, lang_sel):\n",
        "    result = client.predict(transcript_text=text, word_count=word_count, model_sel=model_sel, lang_sel=lang_sel, api_name=\"/summarize\")\n",
        "    return result\n",
        "\n",
        "# Function to punctuate\n",
        "def punctuate_text(text, model_sel):\n",
        "    result = client.predict(transcript=text, model_sel=model_sel, api_name=\"/punctuate\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "3tYC97M8C2J2",
        "outputId": "5dc23cb7-020d-421b-fc91-43017e087bc3"
      },
      "outputs": [],
      "source": [
        "# @title App\n",
        "languages = [\n",
        "    \"English\", \"Persian\", \"French\", \"Spanish\", \"German\", \"Italian\", \"Portuguese\", \"Dutch\", \"Swedish\", \"Danish\",\n",
        "    \"Finnish\", \"Norwegian\", \"Russian\", \"Polish\", \"Turkish\", \"Arabic\", \"Hindi\", \"Chinese\", \"Japanese\", \"Korean\",\n",
        "    \"Thai\", \"Vietnamese\", \"Indonesian\", \"Hebrew\", \"Greek\", \"Czech\", \"Hungarian\", \"Romanian\", \"Bulgarian\", \"Serbian\",\n",
        "    \"Croatian\", \"Slovak\", \"Slovenian\", \"Ukrainian\", \"Lithuanian\", \"Latvian\", \"Estonian\", \"Macedonian\", \"Albanian\",\n",
        "    \"Basque\", \"Catalan\", \"Maltese\", \"Icelandic\", \"Georgian\", \"Armenian\", \"Belarusian\", \"Yiddish\", \"Pashto\", \"Urdu\",\n",
        "    \"Bengali\", \"Punjabi\", \"Tamil\", \"Telugu\", \"Malayalam\", \"Sinhala\", \"Burmese\", \"Lao\", \"Khmer\", \"Mongolian\",\n",
        "    \"Nepali\", \"Marathi\", \"Gujarati\", \"Kannada\", \"Odia\", \"Assamese\", \"Maithili\", \"Kurdish\", \"Azerbaijani\", \"Kazakh\",\n",
        "    \"Uzbek\", \"Turkmen\", \"Tajik\", \"Kyrgyz\", \"Uighur\", \"Tatar\", \"Haitian Creole\", \"Swahili\", \"Hausa\", \"Yoruba\",\n",
        "    \"Zulu\", \"Xhosa\", \"Amharic\", \"Somali\", \"Tigrinya\", \"Shona\", \"Igbo\", \"Malagasy\", \"Quechua\", \"Aymara\", \"Guarani\",\n",
        "    \"Sundanese\", \"Javanese\", \"Filipino\", \"Hmong\", \"Fijian\", \"Tongan\", \"Samoan\", \"Chamorro\", \"Hawaiian\"\n",
        "]\n",
        "languages = sorted(languages)\n",
        "model_selections = [\"gemini-2.0-flash\", \"gemini-2.0-pro-exp-02-05\", \"gemini-2.0-flash-lite\"]\n",
        "\n",
        "lang = 'English'\n",
        "model_sel = 'gemini-2.0-flash'\n",
        "assert model_sel in model_selections, \"Invalid model selection\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# üéôÔ∏è YouTube Persian ASR & NLP via Hugging Face API\")\n",
        "\n",
        "    with gr.Row():\n",
        "        youtube_input = gr.Textbox(label=\"üì∫ Enter YouTube Link\")\n",
        "        transcribe_button = gr.Button(\"üéµ Download & Transcribe\")\n",
        "\n",
        "    transcript_output = gr.Textbox(label=\"üìù Transcription\", interactive=True)\n",
        "    translation_output = gr.Textbox(label=\"üåç Translation\", interactive=False)\n",
        "    summarized_output = gr.Textbox(label=\"üìñ Summarized Text\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        translate_button = gr.Button(\"üåê Translate\")\n",
        "        summarize_button = gr.Button(\"‚úÇÔ∏è Summarize\")\n",
        "        punctuate_button = gr.Button(\"üî§ Restore Punctuation\")\n",
        "\n",
        "    with gr.Row():\n",
        "        word_count_input = gr.Number(value=50, label=\"üìè Summary Length\")\n",
        "        lang_selection = gr.Dropdown(choices=languages, value=lang, label=\"üåé Target Language\")\n",
        "        model_selection = gr.Dropdown(choices=model_selections, value=model_sel, label=\"ü§ñ AI Model\")\n",
        "\n",
        "    # Link functions to buttons\n",
        "    transcribe_button.click(transcribe_audio, inputs=youtube_input, outputs=[transcript_output, translation_output, summarized_output])\n",
        "    translate_button.click(translate_text, inputs=[transcript_output, lang_selection, model_selection], outputs=translation_output)\n",
        "    summarize_button.click(summarize_text, inputs=[transcript_output, word_count_input, model_selection, lang_selection], outputs=summarized_output)\n",
        "    punctuate_button.click(punctuate_text, inputs=[transcript_output, model_selection], outputs=transcript_output)\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        \\n\\n\n",
        "        ---\n",
        "\n",
        "        Powered by NVIDIA‚Äôs **NeMo Fast Conformer**, this tool is optimized for high-quality **Persian ASR (Automatic Speech Recognition)**.\n",
        "\n",
        "        **üìö Trained on 800+ Hours of Speech Data:**\n",
        "        - Common Voice 17 (~300 hours)\n",
        "        - YouTube (~400 hours)\n",
        "        - NasleMana (~90 hours)\n",
        "        - In-house dataset (~70 hours)\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## üìú License & Business Inquiries\n",
        "\n",
        "        This application is licensed under **Creative Commons Attribution-NonCommercial 4.0 (CC BY-NC 4.0)**.\n",
        "        - **üõë Non-Commercial Use Only** ‚Äì Commercial use is not permitted without prior approval.\n",
        "        - **üîó Attribution Required** ‚Äì Credit must be given to FAIM Group, Sharif University of Technology.\n",
        "        - **‚ùå No Derivatives** ‚Äì Modifications or adaptations of this work are not allowed.\n",
        "\n",
        "        üìú Full License Details: [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)\n",
        "\n",
        "        üì© **Business Inquiries:**\n",
        "        If you're interested in commercial applications, please contact us at:\n",
        "        ‚úâÔ∏è **Email:** [saeedzou2012@gmail.com](mailto:saeedzou2012@gmail.com)\n",
        "\n",
        "        ---\n",
        "        \"\"\"\n",
        "    )\n",
        "demo.launch(share=True, debug=True)  # Enables public link"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
